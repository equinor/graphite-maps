{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1e1a788-fdf3-4e14-9e43-983e395219ee",
   "metadata": {},
   "source": [
    "# Auto-Regressive assimilation with EnIF\n",
    "\n",
    "We illustrate `EnIF` methodology and the API through the Auto-Regressive-1 (AR-1) model.\n",
    "The AR-1 is defined by\n",
    "$$u_t = \\phi u_{t-1} + \\epsilon,~~\n",
    " \\epsilon\\sim N(0,1) $$\n",
    "and has a tri-diagonal sparse precision matrix.\n",
    "\n",
    "We will illustrate both the **high-level** API of EnIF, and also the **low-level** API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df0ef3-6a13-4200-82d0-dd9302343754",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdb624eb-02a0-4f75-8a37-7415143a93fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "import scipy as sp\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from graphite_maps.precision_estimation import precision_to_graph\n",
    "from graphite_maps.enif import EnIF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cbad4f-6095-452a-82cf-43604d8ecfe8",
   "metadata": {},
   "source": [
    "We will repeatedly plot\n",
    "- a realization\n",
    "- an ensemble\n",
    "- the ensemble mean\n",
    "- the difference between posterior and prior mean\n",
    "\n",
    "we thus create a function for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a2b1b5-6e56-4558-afbf-c0fd2006209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "def plot_ensemble(Ensemble, d, prior_mean=None):\n",
    "    n, p = Ensemble.shape\n",
    "    u_position = [j for j in range(p)]\n",
    "    ind_obs = np.rint(p / 2).astype(int) - 1\n",
    "    ensemble_mean = np.array(Ensemble.mean(axis=0))\n",
    "    num_plots = 3 if prior_mean is None else 4\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 4))\n",
    "    fig.suptitle('Ensemble inspection & observation', fontsize=16)\n",
    "\n",
    "    ax = fig.add_subplot(1,num_plots,1)\n",
    "    ax.plot(u_position, Ensemble[0,:])\n",
    "    ax.plot(ind_obs, [d], marker='*', ls='none', ms=20)\n",
    "    ax.set_title('Realization #1')\n",
    "    \n",
    "    ax = fig.add_subplot(1,num_plots,2)\n",
    "    for i in range(n):\n",
    "        ax.plot(u_position, Ensemble[i,:], label= \"realization {ind}\".format(ind=i), color=COLORS[0], alpha=0.1)\n",
    "    ax.set_title('All realizations')\n",
    "    ax.plot(ind_obs, [d], marker='*', ls='none', ms=20, color=COLORS[1])\n",
    "    ax_min, ax_max = ax.get_ylim()  # Get y-limits\n",
    "    \n",
    "    ax = fig.add_subplot(1,num_plots,3)\n",
    "    ax.plot(u_position, ensemble_mean)\n",
    "    ax.plot(ind_obs, [d], marker='*', ls='none', ms=20)\n",
    "    ax.set_title('Ensemble mean')\n",
    "\n",
    "    if num_plots == 4:\n",
    "        ax = fig.add_subplot(1,num_plots,4)\n",
    "        ax.plot(u_position, ensemble_mean - prior_mean)\n",
    "        ax.set_title('Posterior mean - prior mean')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368dc490-88ca-44a0-9f5f-c3774203e89b",
   "metadata": {},
   "source": [
    "## Data setup: Auto-regressive simulation\n",
    "\n",
    "We define the parameters of the ensemble based data assimilation with the AR-1\n",
    "- `n`: ensemble or sample size. Increasing will increase the quality of the solution\n",
    "- `p`: the number of AR-1 time-steps, here the dimensions of the problem. Increasing yields a more difficult problem. Traditional ensemble based methods would use localization to deal with high `p`.\n",
    "- `phi`: between `-1` and `1`. `0` yields white noise without dependence. When `abs(phi)` is close to `1` there is strong dependence between dimensions.\n",
    "- - Suggest to try `phi in [-0.99, 0.5, 0, 0.5, 0.99]` and inspect differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f9f566-2361-4600-a25c-775b4afe53be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "n = 100  # Sample size\n",
    "p = 1000   # Dimension\n",
    "phi = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59ea687-cc87-429f-b567-4309f19b32f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate data\n",
    "def rar1(T, phi):\n",
    "    \"\"\"simulate auto-regressive-1.\n",
    "    The first element is simulated from stationary distribution.\n",
    "    \"\"\"\n",
    "    x = np.empty([T])\n",
    "    x[0] = np.random.normal(0, 1 / np.sqrt(1 - phi**2))\n",
    "    for i in range(1, T):\n",
    "        x[i] = phi * x[i - 1] + np.random.normal(0, 1)\n",
    "    return x\n",
    "\n",
    "np.random.seed(42)\n",
    "U = np.array([rar1(T=p, phi=phi) for _ in range(n)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb32fc5e-c20f-4c92-8347-b6a18a6a88c1",
   "metadata": {},
   "source": [
    "We here know the precision exactly, so we may compare our estimates. Note we derive the graph `Graph_u` from the precision, which we would normally just know apriori, while `Prec_u` would often (not always) be unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c9a72-5147-46e8-b8a6-2aa54aca6302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create AR-1 precision matrix\n",
    "Prec_u = sp.sparse.diags(\n",
    "    [np.repeat(-phi, p-1), np.concatenate(([1.0], np.repeat(1.0+phi**2, p-2), [1.0])), np.repeat(-phi, p-1)], \n",
    "    [-1,0,1], shape=(p, p), \n",
    "    format='csc'\n",
    ")\n",
    "\n",
    "# create corresponding graph -- often we only know this\n",
    "Graph_u = precision_to_graph(Prec_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7b5cad-cf31-4262-9a1b-21b8906e9bb6",
   "metadata": {},
   "source": [
    "Create observations, `d`, that are associated with `u`.\n",
    "We here pass a linear map `H` so that we model $d=Hu+\\epsilon$, and $\\epsilon$ has known precision.\n",
    "Note that `H` may be learnt from data using the `fit_H` function.\n",
    "We must then pass realizations `U` and simulated responses `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a776a8ee-38f0-4381-a76a-0003c8c57dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create observation\n",
    "d = np.array([30.0])\n",
    "sd_eps = 1\n",
    "H = np.array([0] * p, ndmin=2)\n",
    "H[0, np.rint(p / 2).astype(int) - 1] = 1  # middle sencor\n",
    "H = sp.sparse.csc_matrix(H)\n",
    "Prec_eps = np.array([1/sd_eps**2], ndmin=2)\n",
    "Prec_eps = sp.sparse.csc_matrix(Prec_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24bdb1b-bb0b-4411-9325-41dc57106446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create responses\n",
    "Y = U@H.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa20e409-3fa7-4dbc-8266-3c40b8a8c038",
   "metadata": {},
   "source": [
    "Let's inspect the sample from the prior, and the observation `d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311ced3b-150b-4422-b199-4a359c6f1609",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ensemble(U, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71527c41-2fbf-4250-b8f4-80405da8adee",
   "metadata": {},
   "source": [
    "## EnKF / Ensemble Smoother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f303f874-ef37-4f3c-bf43-85c5e96a39d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ES(U, Y, d, Cov_epsilon):\n",
    "    # Cross-covariance matrix C_UY has shape (p, m)\n",
    "    n, m = Y.shape\n",
    "    C_UY = np.dot((U - U.mean(axis=0)).T, (Y - Y.mean(axis=0))) / (n - 1)\n",
    "    print(C_UY.shape)\n",
    "\n",
    "    # Compute the covariance of Y\n",
    "    # Covariance matrix C_YY has shape (m, m)\n",
    "    C_YY = np.dot((Y - Y.mean(axis=0)).T, (Y - Y.mean(axis=0))) / (n - 1)\n",
    "\n",
    "    print(C_YY.shape)\n",
    "\n",
    "    # Estimated K\n",
    "    K = C_UY @ np.linalg.inv(C_YY + Cov_epsilon)\n",
    "    print(K.shape)\n",
    "    \n",
    "    # perturb observations\n",
    "    n, m = Y.shape\n",
    "    eps = np.random.normal(loc=0, scale=np.sqrt(Cov_epsilon.diagonal()), size=(n,m))\n",
    "    di = d - eps\n",
    "\n",
    "    U_posterior = np.copy(U)\n",
    "    for i in range(n):\n",
    "        U_posterior[i,:] += K @ (di[i] - Y[i,:])\n",
    "    \n",
    "    return U_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ebf3ac-79ed-442a-9f8d-c01e3fb9588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = U@H.T\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e0ec1f-7305-47db-8fc0-1712e5ec4d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_posterior_es = ES(U, Y, d, np.linalg.inv(Prec_eps.A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b82aa71-a772-4855-a617-04104b8a8050",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_mean = np.array(U.mean(axis=0))\n",
    "plot_ensemble(U_posterior_es, d, prior_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b879750-3857-4bda-b67e-d39bcc715919",
   "metadata": {},
   "source": [
    "## EnIF high-level API\n",
    "\n",
    "The high-level API consists of initialization, usually with a `Graph_u`, the noise precision `Prec_eps` and possibly the map `H`.\n",
    "Then only two functions are needed `fit` and `transport` to arrive an updated (or analysed) ensemble.\n",
    "To think of these know that \n",
    "- `fit` estimates a GMRF model w.r.t. the graph `Graph_u`, and learns a sparse affine map `H`. If `Prec_u` or `H` are passed, they are not re-fitted, but the low-level API can be used to update these if need be.\n",
    "- `transport` takes the prior ensemble `U` and \"transports\" each realization to a realization of the posterior under the fitted GMRF and `H` model. More on the details here in the low-level API section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c3b1f4-0f41-472d-aeba-2d2b7a9ea9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtmap = EnIF(Graph_u = Graph_u, Prec_eps=Prec_eps, H=H)\n",
    "gtmap.fit(U, verbose_level=4)\n",
    "U_posterior_highlevel = gtmap.transport(U, Y, d, seed=42, verbose_level=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53bffd4-bfe2-4170-a75c-34bcdb216d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_mean = np.array(U.mean(axis=0))\n",
    "plot_ensemble(U_posterior_highlevel, d, prior_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb98d96f-86c1-4208-8d1c-69a50339105a",
   "metadata": {},
   "source": [
    "## EnIF low-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b7ab57-c21d-4c39-9677-f69ac5e6ea43",
   "metadata": {},
   "source": [
    "### Sanity check #1: Equality of results\n",
    "\n",
    "We now illustrate the low-level API, and check that it gives the same result as the high-level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b174d15-fb96-41c3-a819-add84665aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtmap_lowlevel = EnIF(Graph_u = Graph_u, Prec_eps=Prec_eps, H=H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd137239-9b80-4950-8e99-031f853b545e",
   "metadata": {},
   "source": [
    "#### Fit\n",
    "When we call `fit`, we may estimate `Prec_u` as a GMRF w.r.t. `Graph_u`.\n",
    "Also during `fit`, the mapping `H` may be estimated using `fit_H` that employes the LASSO for learning a sparse representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aff8f47-17a0-4d7e-9a39-853286931023",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtmap_lowlevel.fit_precision(U)\n",
    "if gtmap_lowlevel.H is None:\n",
    "    gtmap_lowlevel.fit_H(U, U@H.T) # simulations Y = U@H.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c80b8e-150d-4fb5-bd38-01907e58af8b",
   "metadata": {},
   "source": [
    "#### Transport\n",
    "\n",
    "The name `transport` comes from the field of measure-transport.\n",
    "It does make sense in this context, because the function indeed transports each realization of prior to a realization of the posterior w.r.t. the GMRF on $(u,d)$ estimated by `fit`.\n",
    "\n",
    "`transport` consists of three functions\n",
    "- `pushforward_to_canonical`: transport realizations to \"canonical\" space\n",
    "- `update_canonical`: update each canonical realization to a realization from the posterior, _and_ update the precision `Prec_u`\n",
    "- `pullback_from_canonical`transport realizations back to physical space\n",
    "\n",
    "where in-between, we sample some specific noisy residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ba9b0a-005a-4319-81e9-2252a260659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical = gtmap_lowlevel.pushforward_to_canonical(U)\n",
    "\n",
    "# Work out residuals and associate unexplained variance\n",
    "residual = gtmap_lowlevel.response_residual(U, Y)\n",
    "eps = gtmap_lowlevel.generate_observation_noise(n, seed=42)\n",
    "residual_noisy = residual + eps\n",
    "\n",
    "canonical_posterior = gtmap_lowlevel.update_canonical(canonical, residual_noisy, d)\n",
    "U_posterior_lowlevel = gtmap_lowlevel.pullback_from_canonical(canonical_posterior, iterative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90875598-e0ea-4cd9-a0db-4e6c21d74eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical_posterior.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ef04bf-6ca9-4dff-95b4-24563d90e3ab",
   "metadata": {},
   "source": [
    "Note that `transport` could have used the Kalman-filter equations (conditioning with a multivariate Gaussian in the mean-precision parametrization).\n",
    "It is however much more numerically efficient (and stable) to employ the Information-filter equations (conditioning with a multivariate Gaussian in the canonical parametrization) when working with a GMRF.\n",
    "\n",
    "We plot to check the results are like before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d41b8-d778-47bd-800f-a6aa830a0a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ensemble(U_posterior_lowlevel, d, prior_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3233851-71e8-49a3-ac5a-2c091ff5b94d",
   "metadata": {},
   "source": [
    "The results look identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a76c98-f7f2-47b0-8508-41afacada6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(U_posterior_lowlevel, U_posterior_highlevel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20be66b8-509f-42c6-baf9-e936a1fe2375",
   "metadata": {},
   "source": [
    "And indeed they are identical. When `seed` is different, the results should be distributionally equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d948e-34cb-4bbf-b3a2-d05e6b57722a",
   "metadata": {},
   "source": [
    "### Sanity check #2: Using true precision\n",
    "\n",
    "For this case, we do indeed have access to the true prior precision of the AR-1 process.\n",
    "It is possible to pass this to `EnIF` upon initialization, and if `H` too is provided it is not necessary to run `fit`.\n",
    "The case of a known precision is sometimes known, e.g. when doing pure parameter estimation, the prior we are sampling from can indeed be known, and is often transformed (for good reasons) to a multivariate standard normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeed2f7-7e31-4709-85dc-d6b3fedde42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtmap_prec_known = EnIF(Prec_u = Prec_u, Prec_eps=Prec_eps, H=H)\n",
    "\n",
    "U_posterior = gtmap_prec_known.transport(U, Y, d)\n",
    "\n",
    "plot_ensemble(U_posterior, d, prior_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9336bfed-3dcd-4095-bc79-81b0c933edf8",
   "metadata": {},
   "source": [
    "The results are _almost_ identical.\n",
    "Note however that there is zero noise in the update.\n",
    "This is because we have not estimated anything from data -- both `Prec_u` and `H` was provided apriori, exactly defining the Gaussian on $(u,d)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa7abcc-f624-4b99-9ca6-0fde85de95bc",
   "metadata": {},
   "source": [
    "### Sanity check #3: Pullback of pushforward without update at canonical\n",
    "\n",
    "We just decomposed `transport` to its three main parts, a pushforward, an update, and a pullback.\n",
    "It is reasonable to think that if we skip the `update` in the middle,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f38d6-84b9-4354-b36e-ed58b5185530",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtmap_pullpush = EnIF(Prec_u = Prec_u, Prec_eps=Prec_eps, H=H)\n",
    "canonical = gtmap_pullpush.pushforward_to_canonical(U)\n",
    "U_posterior = gtmap_pullpush.pullback_from_canonical(canonical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815659fe-ae4c-43a0-92d3-370a52871c77",
   "metadata": {},
   "source": [
    "then the pullback of what we pushforwarded, should be the same as what we input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6a50fe-2c7a-4ece-ae67-c93af2a60c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(U, U_posterior, atol=1e-12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15919a3-0236-4635-84a7-489d9bb08b15",
   "metadata": {},
   "source": [
    "which indeed seems to be the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de2dd91-d617-4caf-aacd-5897a139b7e7",
   "metadata": {},
   "source": [
    "## Estimating a sparse linear map\n",
    "\n",
    "If `H` is not given, then it must be estimated from data `U` and `Y`.\n",
    "We seek a linear map that learns\n",
    "$$H = E[\\nabla_u h(u)]$$ \n",
    "for some conceptual potentially non-linear map $h:u\\mapsto y$.\n",
    "Furthermore, we seek a sparse representation `H`, so that the posterior `Prec_u` retains sparsity.\n",
    "To this end, `fit_H` implements linear L1 regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0933c0-047b-4573-b720-6781f8946f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtmap_uninformed = EnIF(Graph_u=Graph_u, Prec_eps=Prec_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2278eb05-a188-48b7-b9a7-f4d25f732cbd",
   "metadata": {},
   "source": [
    "Note that neither `Prec_u` or `H` is passed.\n",
    "As such, they should both be learnt from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7619cf-a653-43d2-94ef-525a97bda548",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtmap_uninformed.fit(U, Y, verbose_level=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5403b26-2d7d-40b2-baae-57b44006be4c",
   "metadata": {},
   "source": [
    "Print the true and the (hopefully sparse) learnt map, to see if it looks correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e4a15-fa6c-436d-8b3d-62e8fa1f9580",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original sparse matrix\")\n",
    "print(H) # true (unknown) map\n",
    "print(\"Estimated sparse matrix\")\n",
    "print(gtmap_uninformed.H) # estimated (sparse) map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbe1def-eced-402a-a3f3-a6203bfe05d1",
   "metadata": {},
   "source": [
    "As we see, the sparsity structure has been identified, and the value is very close to `1`.\n",
    "We may then employ it for `transport` of the prior ensemble to a posterior ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92d5b58-ad0b-4614-a7d8-71cc03968e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_posterior = gtmap_uninformed.transport(U, Y, d)\n",
    "plot_ensemble(U_posterior, d, prior_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b5ac5a-76f6-411f-a818-601424496e54",
   "metadata": {},
   "source": [
    "## Estimating a sparse linear map - Fast with influence adapted boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56783d62-2106-41b3-bfaf-fcde94d8f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtmap_uninformed_2 = EnIF(Graph_u=Graph_u, Prec_eps=Prec_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce9f109-03d5-430a-9098-4fc140a7fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtmap_uninformed_2.fit(U, Y, learning_algorithm=\"influence-boost\", verbose_level=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76df6ebe-6dff-46c4-b787-4611a06b16ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original sparse matrix\")\n",
    "print(H) # true (unknown) map\n",
    "print(\"Estimated sparse matrix\")\n",
    "print(gtmap_uninformed_2.H) # estimated (sparse) map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321fd893-db01-4415-91d6-ed99495a3743",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_posterior = gtmap_uninformed_2.transport(U, Y, d)\n",
    "plot_ensemble(U_posterior, d, prior_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9047cba2-f618-4546-9ecb-ef9886a94dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
